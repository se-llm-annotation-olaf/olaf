# OLAF: Operationalization for LLM-Based Annotation Framework

OLAF is a conceptual and methodological framework for treating Large Language Model based annotation as a measurable and reproducible process in Empirical Software Engineering.

The framework introduces six operational dimensions:
- Reliability
- Consensus
- Aggregation
- Transparency
- Calibration
- Drift

OLAF positions LLMs as measurement instruments rather than purely automated annotators and provides guidance for rigorous empirical evaluation.

## Paper
**OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering**  
Mia Mohammad Imran, Tarannum Shaila Zaman  
Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE), 2026

## Website
This repository hosts the official project website:
[https://se-llm-annotation-olaf.github.io/olaf/](https://se-llm-annotation-olaf.github.io/olaf/)


## Citation
```bibtex
@inproceedings{imran2025olaf,
  title={OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering},
  author={Imran, Mia Mohammad and Zaman, Tarannum Shaila},
  booktitle={Proceedings of the 3rd IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering (WSESE)},
  year={2026}
}
```
